[
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "##Packages Used\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(exact2x2)\n\nLoading required package: exactci\nLoading required package: ssanv\nLoading required package: testthat\n\nAttaching package: 'testthat'\n\nThe following object is masked from 'package:dplyr':\n\n    matches\n\nThe following object is masked from 'package:purrr':\n\n    is_null\n\nThe following objects are masked from 'package:readr':\n\n    edition_get, local_edition\n\nThe following object is masked from 'package:tidyr':\n\n    matches\n\n\n##Importing the Data\n\nttdata <- data.frame(tidytuesdayR::tt_load('2023-02-14')$age_gaps)\n\n--- Compiling #TidyTuesday Information for 2023-02-14 ----\n\n\n--- There is 1 file available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `age_gaps.csv`\n\n\n--- Download complete ---\n\n\n##Viewing the Data\n\n# Gives a summary of the data\nglimpse(ttdata)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…\n\n# Checks to ensure all characters are defined at \"man\" and \"woman\"\nunique(ttdata$character_1_gender)\n\n[1] \"woman\" \"man\"  \n\nunique(ttdata$character_2_gender)\n\n[1] \"man\"   \"woman\"\n\n# Checks for any missing values\nnaniar::gg_miss_var(ttdata)\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\nℹ The deprecated feature was likely used in the naniar package.\n  Please report the issue at <\u001b]8;;https://github.com/njtierney/naniar/issues\u0007https://github.com/njtierney/naniar/issues\u001b]8;;\u0007>.\n\n\n\n\n\nAccording to the gg_miss_var() function in the naniar package, we see that there are no missing values in any of the variables.\nWe can forgo usual data repair.\n##Objectives\nAccording to the variables, we may be interested in seeing the proportion of on-screen romances that occur between heterosexual and homosexual couples presented on the big screen. We may also wonder if these relationships are typical of this data set. We also may notice that a wide age gap between these on-screen relationships.\n###Questions:\n####1. What proportion of movies depict same-sex relationships? Is this surprising?\n####2. What happens when er compare these proportions after and before the year 2000? Is there a difference?\n####3. What are the odds of having an excessively high age difference given relationship type?\n###Acquiring Needed Data\n\ndt <- ttdata %>%\n# Chooses only variables of interest\n                  select(character_1_gender,character_2_gender,age_difference,release_year) %>%\n# Creates a new variables based on whether the genders of the two characters are the same\n                  mutate(relate_type = ifelse(character_1_gender == character_2_gender,\"same\",\"different\"),\n# Changes the parameter to a bivariate outcome: `before 2000` and `2000 and after`\n                         release_year = ifelse(release_year >= 2000,\n                                               \"2000 or after\",\n                                               \"before 2000\"),\n# Changes the parameter to a bivariate outcome: `0-14` and `15+`\n                         age_difference = ifelse(age_difference < 15,\n                                                 \"0-14\",\n                                                 \"15+\"))\n\nHere, we select for only the data that suits our needs. We only want to see the characters’ genders and their age differences. In order for our analyses to work, we must convert the age_difference variable into a binary outcome, so we condition the age differences of the actors into 2 categories: 0-14 and 15+. This way, we can construct a 2-way table to represent the distribution of age differences based on on-screen relationship pairs.\n###1.\n###Representing the Data\n\n# Converts the data into a 2-way table representing each pair\npart1 <- with(dt,table(character_1_gender,character_2_gender))\n# Makes the table more readable\nnames(dimnames(part1)) <- c(\"Character 1\",\"Character 2\")\n# Shows row and column totals\npart1 %>% addmargins()\n\n           Character 2\nCharacter 1  man woman  Sum\n      man     12   929  941\n      woman  203    11  214\n      Sum    215   940 1155\n\n\nThe table above represents the the number of on-screen romances. We can see that only 12 films represent gay relationships and that 11 films represent lesbian relationships, meaning there are a total of 23 films with some kind of homosexual representation in these 1155 films. It may be helpful to examine their relative proportions:\n\n# Shows cell proportions\npart1_props <- prop.table(part1)\npart1_props\n\n           Character 2\nCharacter 1        man      woman\n      man   0.01038961 0.80432900\n      woman 0.17575758 0.00952381\n\n\nHere, we see that less than 2% of these 1155 films had homosexual representation of some sort. Using a binomial distribution, we can determine if this is an uncommon occurrence:\n\npart1 <- part1 %>% addmargins()\n# Simple proportion test using 95% Confidence Interval\nDescTools::BinomCI(part1[1,1]+part1[2,2],part1[3,3])\n\n            est     lwr.ci     upr.ci\n[1,] 0.01991342 0.01330551 0.02970422\n\n\nBased on the calculations above, we can say that with 95% confidence, the true proportion of films with gay representation lies inside the interval 1.33% and 2.97%. This is still a very small percentage, so we might conclude that gay representation is still very low.\nBut maybe more and more films have begun to prominently display gay relationships since 2000. How can we show this?\n###2.\n###Representing the Data\n\n# Converts the data into a 2-way table representing on-screen relationships\n# stratified by release year and relationship type\npart2 <- with(dt,table(relate_type,release_year))\n# Makes the table more readable\nnames(dimnames(part2)) <- c(\"Relationship Type\",\"Release Year\")\n# Shows row and column totals\npart2 %>% addmargins()\n\n                 Release Year\nRelationship Type 2000 or after before 2000  Sum\n        different           743         389 1132\n        same                 22           1   23\n        Sum                 765         390 1155\n\n\nWe can choose to display the data as a table, but it can be difficult to quickly interpret the potential relationships between variables. Often, data in 2-way tables are displayed as mosaic plots for this reason.\n\n# Constructs a mosaic plot of the data\nmosaicplot(data=dt, release_year ~ relate_type,\n           main = \"Distribution of On-Screen Relationships \\n by Release Date and Type\",\n           xlab = \"Release Year\",\n           ylab = \"Relationship Type\")\n\n\n\n\nNow, we can easily see that heterosexual relationships are still much more common than same sex relationships, but compared to before 2000, there appear to be more same sex relationships in 2000 and after.\nNow let’s see if this increased number of same sex couples represented on screen is due to some factor other than the increased number of films produced after 2000. We can test this by using a X^2 test for independence.\n\n# Performs the continuity corrected X^2 test for independence\nchisq.test(part2)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  part2\nX-squared = 7.7886, df = 1, p-value = 0.005258\n\nfisher.exact(part2, midp=TRUE)\n\n\n    Central Fisher's Exact Test (mid-p version)\n\ndata:  part2\np-value = 0.0009636\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.00415314 0.47003856\nsample estimates:\nodds ratio \n0.08691912 \n\n\nHere, we use two tests for independence: the standard X^2 procedure and the Fisher’s exact test. The Fisher’s exact test is a special form of the X^2 test used when one or more of the cell counts is less than 5. Based on the results of the X^2 test displayed above, we conclude that same sex representation is not independent from release year.\n\n# Shows the expected values used in the X^2 test\nchisq.test(part2)$expected\n\n                 Release Year\nRelationship Type 2000 or after before 2000\n        different     749.76623  382.233766\n        same           15.23377    7.766234\n\n# Shows the residuals from the X^2 test\nchisq.test(part2)$res\n\n                 Release Year\nRelationship Type 2000 or after before 2000\n        different    -0.2471064   0.3460848\n        same          1.7335779  -2.4279613\n\n\nAccording to the residuals presented in the table above, same sex relationships showed a higher probability of occurrence after 2000 than before 2000, indicating an increase in the number of these relationships since the year 2000.\n###3.\n###Representing the data\n\n# Converts the data into a 2-way table representing on-screen relationships\n# stratified by age difference and relationship type\npart3 <- with(dt,table(relate_type,age_difference))\n# Makes the table more readable\nnames(dimnames(part3)) <- c(\"Relationship Type\",\"Age Difference\")\n# Shows row and column totals\npart3 %>% addmargins()\n\n                 Age Difference\nRelationship Type 0-14  15+  Sum\n        different  832  300 1132\n        same        14    9   23\n        Sum        846  309 1155\n\n\nAbove, we can see the 2-way table for age difference vs. relationship type, and below is the mosaic plot.\n\n# Constructs a mosaic plot of the data\nmosaicplot(data=dt, age_difference~ relate_type,\n           main = \"Distribution of On-Screen Relationships \\n by Age Difference and Type\",\n           xlab = \"Age Difference\",\n           ylab = \"Relationship Type\")\n\n\n\n\nUsing an odds ratio, we may be able to identify a relationship between age difference and relationship type.\n\nepitools::oddsratio(part3)\n\n$data\n                 Age Difference\nRelationship Type 0-14 15+ Total\n        different  832 300  1132\n        same        14   9    23\n        Total      846 309  1155\n\n$measure\n                 odds ratio with 95% C.I.\nRelationship Type estimate     lower    upper\n        different 1.000000        NA       NA\n        same      1.792952 0.7319929 4.166928\n\n$p.value\n                 two-sided\nRelationship Type midp.exact fisher.exact chi.square\n        different         NA           NA         NA\n        same       0.1934065    0.2314329  0.1755846\n\n$correction\n[1] FALSE\n\nattr(,\"method\")\n[1] \"median-unbiased estimate & mid-p exact CI\"\n\n\nAccording to the analyses above, the data fail to establish an association between relationship type and actors’ age difference."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Hello! I am a second year MPH student at UGA concentrating in Biostatistics. My goal is to work with data management systems in hospitals to streamline the process of healthcare data across several platforms."
  },
  {
    "objectID": "aboutme.html#experience",
    "href": "aboutme.html#experience",
    "title": "About me",
    "section": "Experience",
    "text": "Experience\nMuch of what I have learned about coding in R was from this website. DataCamp is a free resource for high quality programming practice. I would recommend making an account if you would like foundational knowledge or more practice with R, though DataCamp is not relegated to just R."
  },
  {
    "objectID": "aboutme.html#interests",
    "href": "aboutme.html#interests",
    "title": "About me",
    "section": "Interests",
    "text": "Interests\nIn my past time, I garden with my family. We endeavor to maintain self-sufficient-style gardening in which we cycle the types of crops we grow to accommodate our own needs each season. In addition, I grow fruit trees like lemons, pomegranates, and apples from seed."
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "The data comes from: https://news.gallup.com/poll/1645/guns.aspx The figure comes from: https://fivethirtyeight.com/features/support-for-gun-control-will-likely-rise-after-uvalde-but-history-suggests-it-will-fade/ This is the original figure: \n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nHere are the methods I used to try to replicate the above figure. While it is not a perfect replicate, I am proud of the work I have put forth. I used StackOverflow to help guide me whenever I could not think of a solution or did not know what function to use.\n\n# importing the data\nraw1 <- readxl::read_xlsx(\"data/Raw_Data.xlsx\")\n# viewing the data\ndplyr::glimpse(raw1)\n\nRows: 40\nColumns: 5\n$ Date          <chr> \"2022 Oct 3-20\", \"2022 Jun 1-20\", \"2021 Oct 1-19\", \"2020…\n$ `More Strict` <dbl> 57, 66, 52, 57, 64, 63, 61, 67, 60, 55, 55, 47, 49, 49, …\n$ `Less Strict` <dbl> 10, 8, 11, 9, 7, 7, 8, 4, 5, 10, 11, 14, 13, 13, 6, 11, …\n$ `Kept as Now` <dbl> 32, 25, 35, 34, 28, 29, 30, 28, 33, 34, 33, 38, 37, 37, …\n$ `No Opinion`  <chr> \"1\", \"*\", \"1\", \"*\", \"1\", \"1\", \"2\", \"1\", \"1\", \"1\", \"*\", \"…\n\n# making the data into a date format\ndata1 <- raw1 %>%\n            dplyr::mutate(Date = gsub(\"\\\\-.*\",\"\",Date),\n                   Date = as.Date(Date,format=\"%Y %b %d\"),\n# making sure all data is class c(double, numeric)\n                   `No Opinion` = as.numeric(`No Opinion`))\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `No Opinion = as.numeric(`No Opinion`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# making sure the dat conversion worked\ndplyr::glimpse(data1)\n\nRows: 40\nColumns: 5\n$ Date          <date> 2022-10-03, 2022-06-01, 2021-10-01, 2020-09-30, 2019-10…\n$ `More Strict` <dbl> 57, 66, 52, 57, 64, 63, 61, 67, 60, 55, 55, 47, 49, 49, …\n$ `Less Strict` <dbl> 10, 8, 11, 9, 7, 7, 8, 4, 5, 10, 11, 14, 13, 13, 6, 11, …\n$ `Kept as Now` <dbl> 32, 25, 35, 34, 28, 29, 30, 28, 33, 34, 33, 38, 37, 37, …\n$ `No Opinion`  <dbl> 1, NA, 1, NA, 1, 1, 2, 1, 1, 1, NA, 1, 1, 2, 2, 2, 2, 1,…\n\n\n\n# plotting data\nggplot(data1) +\n# draws line and outline for \"Less strict\" responses\n      geom_line(aes(x=Date,y=`Less Strict`),size=3,color=\"#FFFFFF\") +\n      geom_line(aes(x=Date,y=`Less Strict`),size=1,color=\"maroon3\") +\n# draws line and outline for \"Kept as now\" responses\n      geom_line(aes(x=Date,y=`Kept as Now`),size=3,color=\"#FFFFFF\") +\n      geom_line(aes(x=Date,y=`Kept as Now`),size=1,color=\"#666666\") +\n# draws line and outline for \"More strict\" responses\n      geom_line(aes(x=Date,y=`More Strict`),size=3,color=\"#FFFFFF\") +\n      geom_line(aes(x=Date,y=`More Strict`),size=1,color=\"green4\") +\n# adds verticle lines for mass shooting events\n      geom_vline(xintercept=as.Date(\"1999-04-10\"),linetype=3) +\n      geom_vline(xintercept=as.Date(\"2012-12-14\"),linetype=3) +\n      geom_vline(xintercept=as.Date(\"2018-02-14\"),linetype=3) +\n# gets rid of grey background\n      theme_minimal() +\n# allows for x-axis manipulation and titling\n      scale_x_date(limits=as.Date(c(\"1990-01-01\",\"2022-04-01\")),\n                   breaks=as.Date(c(\"1995-01-01\",\"2000-01-01\",\"2005-01-01\",\n                                    \"2010-01-01\",\"2015-01-01\",\"2020-01-01\")),\n                   labels=c(\"1995\",\"2000\",\"2005\",\"2010\",\"2015\",\"2020\")) +\n# allows for y-axis manipulation and titling\n      scale_y_continuous(breaks = c(0,10,20,30,40,50,60,70)) +\n# adds the figure title\n      labs(title=\"Most Americans support stricter gun laws\",\n           subtitle=\"Share of respondents who say the sale of firearmsshould be made more strict, less \\n strict or kept as they ar now, 1991-2021\") +\n# removes axes titles\n      theme(axis.title.x=element_blank(),\n            axis.title.y=element_blank(),\n            plot.title=element_text(face=\"bold\"),\n# removes the legend\n            legend.position=\"none\",\n# gets rid of minor gridlines and x-axis major gridlines\n            panel.grid.minor=element_blank(),\n            panel.grid.major.x=element_blank(),\n            panel.border=element_blank(),\n# defines x-axis with bold line\n            axis.line.x=element_line(size=0.5, linetype = \"solid\")) +\n# labels the verticle lines representing mass shooting events\n      geom_label(aes(x=as.Date(\"1998-06-10\"),label=\"Columbine \\n shooting\",\n                               y=73),fill=\"#FFFFFF\",label.size=NA,hjust=0) +\n      geom_label(aes(x=as.Date(\"2012-12-14\"),label=\"Sandy Hook \\n shooting\",\n                               y=73),fill=\"#FFFFFF\",label.size=NA,hjust=0.8) +\n      geom_label(aes(x=as.Date(\"2017-04-14\"),label=\"Parkland \\n shooting\",\n                               y=73),fill=\"#FFFFFF\",label.size=NA,hjust=0) +\n# names the lines based on responses\n      geom_label(aes(x=as.Date(\"2021-01-01\"),label=\"More \\n strict\",\n                               y=51),fill=\"#FFFFFF\",color=\"green4\",label.size=NA,hjust=0,\n                 fontface=\"bold\") +\n      geom_label(aes(x=as.Date(\"2021-01-01\"),label=\"Less \\n strict\",\n                               y=12),fill=\"#FFFFFF\",color=\"maroon3\",label.size=NA,hjust=0,\n                 fontface=\"bold\") +\n      geom_label(aes(x=as.Date(\"2021-01-01\"),label=\"Kept as \\n now\",\n                               y=34),fill=\"#FFFFFF\",color=\"#666666\",label.size=NA,hjust=0,\n                 fontface=\"bold\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\nRemoved 2 rows containing missing values (`geom_line()`).\nRemoved 2 rows containing missing values (`geom_line()`).\nRemoved 2 rows containing missing values (`geom_line()`).\nRemoved 2 rows containing missing values (`geom_line()`).\nRemoved 2 rows containing missing values (`geom_line()`)."
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "# Loading the \"dslabs\", \"tidyverse\", and \"ggplot2\" packages\nlibrary(dslabs)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\n\n# Bring up a help page describing the data\nhelp(gapminder)\n\n# Provides an overview of the data\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n# Provides a summary of the data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n# Identifies the type of object we are dealing with\nclass(gapminder)\n\n[1] \"data.frame\"\n\n# Assigns all of the data pertaining to African countries from \n# gapminder to a new data frame\nafricadata <- gapminder %>%\n                  filter(continent == \"Africa\")\n\n# Assures the isolated values are correctly identified\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n# Assigns the variables `infant_mortality` and `life_expectancy` \n# to a new data frame\ninfMort <- africadata %>%\n               select(infant_mortality,life_expectancy)\n# Assures the variables have been added to the new data frame\n# correctly\nstr(infMort)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(infMort)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\n# Assigns the variables `population` and `life_expectancy` \n# to a new data frame\npop <- africadata %>%\n           select(population,life_expectancy)\n\n# Assigns the variables `population` and `life_expectancy` \n# to a new data frame\nstr(pop)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(pop)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\n\n# Creates a scatterplot of the data with `infant_mortality` as the \n# independent variable and `life_expectancy` as the dependent variable.\nggplot(data=infMort, aes(x=infant_mortality,y=life_expectancy)) +\n  geom_point()\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n# Creates a scatterplot of the data with log-scale `population` as the \n# independent variable and `life_expectancy` as the dependent variable.\nggplot(data=pop, aes(x=log(population),y=life_expectancy)) +\n  geom_point()\n\nWarning: Removed 51 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n# Identifies the columns in which at least 1 observation is recorded\n# as missing (NA) based on the year\nafricadata %>%\n    group_by(year) %>%\n    summarise(missing = sum(is.na(across(.cols = everything())))) %>%\n    filter(missing == 0)\n\n# A tibble: 11 × 2\n    year missing\n   <int>   <int>\n 1  1999       0\n 2  2000       0\n 3  2001       0\n 4  2002       0\n 5  2003       0\n 6  2004       0\n 7  2005       0\n 8  2006       0\n 9  2007       0\n10  2008       0\n11  2009       0\n\n# Creates a new data frame that collects all the observations made \n# in the year 2000\nafricadata2000 <- africadata %>%\n                      filter(year == 2000)\n\n# Ensures that the observations where filtered correctly from the \n# step above\nstr(africadata2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\nsummary(africadata2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n# Creates a scatterplot of the data with `infant_mortality` as the \n# independent variable and `life_expectancy` as the dependent variable\n# based on the `africadata2000` data frame.\nggplot(data=africadata2000, aes(x=infant_mortality,y=life_expectancy)) +\n  geom_point()\n\n\n\n\n\n# Creates a scatterplot of the data with log-scale `population` as the \n# independent variable and `life_expectancy` as the dependent variable \n# based on the `africadata2000` data frame.\nggplot(data=africadata2000, aes(x=log(population),y=life_expectancy)) +\n  geom_point()\n\n\n\n\n\n# Fits a linear model to the data frame using `life_expectancy` as\n# the outcome and `infant_mortality` as the predictor\nfit1 <- lm(data=africadata2000,life_expectancy ~ infant_mortality)\n\n# Fits a linear model to the data frame using `life_expectancy` as\n# the outcome and `population` as the predictor\nfit2 <- lm(data=africadata2000,life_expectancy ~ population)\n\n# Provides the summary for the fitted models\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africadata2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      71.29331    2.42611  29.386  < 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ population, data = africadata2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 5.593e+01  1.468e+00  38.097   <2e-16 ***\npopulation  2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\n\n#this comment and code below was added by Jacob Matta\n\n#downloand the broom package to make a tibble out of the lm() function\nlibrary(broom)\n\n#apply the tidy function to fit1 and fit2 which will give you a tabular data representation of the coefficients \ntidy_fit1 <- tidy(fit1)\ntidy_fit2 <- tidy(fit2)\n\n#apply the augment function to fit1 and fit2 to get a fitted values and residuals for each  point in the regression\naugment_fit1 <- augment(fit1)\naugment_fit2 <- augment(fit2)\n\n#apply the glance function to compute several summary statistics such as R, R^2 and p-value\nglance_fit1 <- glance(fit1)\nglance_fit2 <- glance(fit2)\n\n#notice that the broom package functions tidy, augment and glance help clean the lm function by turning coefficients, fitted values, residuals, and summary statistics into a tabular form\n\nBased on the models above, insufficient data is acquired to draw a meaningful conclusion between life expectancy and population size. Conversely, we can conclude that there is a negative association between life expectancy and infant mortality."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Hello!\nAnd welcome to my website.\n\nFeel free to take a look around and explore!\nWelcome to my website and data analysis portfolio.\n\nPlease use the Menu Bar above to look around.\nHave fun!"
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "Data Anlaysis Exercise - Module 4",
    "section": "",
    "text": "This data, from NCHS, shows provisional death counts for the US. These data are obtained from the CDC website, data.CDC.org. Within, you can find COVID-19-related deaths separated by education, age, sex, and race. Data was collected as early as January 1st, 2020 and continued until January 30th, 2021. The data was last updated February 3rd, 2021.\n\nlibrary(readr)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ dplyr   1.1.0\n✔ tibble  3.1.8     ✔ stringr 1.4.1\n✔ tidyr   1.2.1     ✔ forcats 0.5.2\n✔ purrr   0.3.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n# Imports the raw data set. The original data set is a CSV file.\nraw_data <- read_csv(\"data/AH_Provisional_COVID-19_Deaths_by_Educational_Attainment__Race__Sex__and_Age.csv\")\n\nRows: 224 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): Data as of, Start Date, End Date, Education Level, Race or Hispanic...\ndbl (2): COVID-19 Deaths, Total Deaths\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Shows the classes of the variables.\nglimpse(raw_data)\n\nRows: 224\nColumns: 9\n$ `Data as of`              <chr> \"02/03/2021\", \"02/02/2021\", \"02/02/2021\", \"0…\n$ `Start Date`              <chr> \"01/01/2020\", \"01/01/2020\", \"01/01/2020\", \"0…\n$ `End Date`                <chr> \"01/30/2021\", \"01/30/2021\", \"01/30/2021\", \"0…\n$ `Education Level`         <chr> \"Associate degree or some college\", \"Associa…\n$ `Race or Hispanic Origin` <chr> \"Hispanic\", \"Hispanic\", \"Hispanic\", \"Hispani…\n$ Sex                       <chr> \"Female\", \"Female\", \"Female\", \"Female\", \"Mal…\n$ `Age Group`               <chr> \"0-17 years\", \"18-49 years\", \"50-64 years\", …\n$ `COVID-19 Deaths`         <dbl> 0, 423, 857, 1793, 0, 737, 1592, 2655, 0, 82…\n$ `Total Deaths`            <dbl> 2, 3117, 4153, 10225, 1, 5676, 6183, 11544, …\n\n# Creates a new data set with the variables we would like to keep. In an effort to be \n# more user friendly, the variable names have been converted to all lowercase with no \n# spaces. Also, some variables have been converted to factor classes.\nnew_data <- raw_data %>%\n    # Changes the variable names and makes some factors.\n           mutate(education_level = as.factor(`Education Level`),\n                  race_origin = as.factor(`Race or Hispanic Origin`),\n                  sex = as.factor(`Sex`),\n                  age_group = as.factor(`Age Group`),\n                  covid_deaths = `COVID-19 Deaths`,\n                  total_deaths = `Total Deaths`\n                  ) %>%\n    # Pushes only the properly formatted variables to the new data set.\n           select(education_level,race_origin,sex,age_group,covid_deaths,total_deaths)\n# Shows a summary of the variables included in the dataset.\nglimpse(new_data)\n\nRows: 224\nColumns: 6\n$ education_level <fct> Associate degree or some college, Associate degree or …\n$ race_origin     <fct> Hispanic, Hispanic, Hispanic, Hispanic, Hispanic, Hisp…\n$ sex             <fct> Female, Female, Female, Female, Male, Male, Male, Male…\n$ age_group       <fct> 0-17 years, 18-49 years, 50-64 years, 65 years and ove…\n$ covid_deaths    <dbl> 0, 423, 857, 1793, 0, 737, 1592, 2655, 0, 82, 176, 362…\n$ total_deaths    <dbl> 2, 3117, 4153, 10225, 1, 5676, 6183, 11544, 0, 591, 79…\n\nsummary(new_data)\n\n                         education_level\n Associate degree or some college:56    \n Bachelor’s degree or more       :56    \n High school graduate/GED or less:56    \n Unknown                         :56    \n                                        \n                                        \n                                        \n                                                 race_origin     sex     \n Hispanic                                              :32   Female:112  \n Non-Hispanic American Indian or Alaska Native         :32   Male  :112  \n Non-Hispanic Asian                                    :32               \n Non-Hispanic Black                                    :32               \n Non-Hispanic Native Hawaiian or Other Pacific Islander:32               \n Non-Hispanic White                                    :32               \n Other/Unknown                                         :32               \n             age_group   covid_deaths       total_deaths     \n 0-17 years       :56   Min.   :    0.00   Min.   :     0.0  \n 18-49 years      :56   1st Qu.:    3.75   1st Qu.:   112.0  \n 50-64 years      :56   Median :   81.00   Median :   817.5  \n 65 years and over:56   Mean   : 1880.20   Mean   : 15665.8  \n                        3rd Qu.:  627.00   3rd Qu.:  4997.5  \n                        Max.   :76871.00   Max.   :670295.0"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "FluAnalysis",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#outcomes-of-interest",
    "href": "fluanalysis/code/exploration.html#outcomes-of-interest",
    "title": "FluAnalysis",
    "section": "Outcomes of Interest",
    "text": "Outcomes of Interest\n~Body Temperature (cont.)\n~Nausea (binary, yes/no)"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#potential-predictors",
    "href": "fluanalysis/code/exploration.html#potential-predictors",
    "title": "FluAnalysis",
    "section": "Potential Predictors",
    "text": "Potential Predictors\n~Chills/Sweats (binary, yes/no)\n~Vomiting (binary, yes/no)\n~Fatigue (binary, yes/no)\n~Swollen Lymph Nodes (binary, yes/no)\n~Weakness (cat.)\n~Cough Intensity (cat.)\n\nThe Outcomes\nWe can get an idea of what analyses we might want to do by first exploring the proportion of patients that experience each predictor variable, relative to the two outcomes of interest (ie. Body Temperature and Nausea).\nLet’s first take a look at how patients’ body temperatures are distributed. We can do this by using base r’s plot(), specifying BodyTemp using $. I’ve introduced two vertical lines, one representing the mean (dark blue) and one representing the median (light blue). This was done by inserting a vertical abline() in conjunction with mean() and median().\nWe must also ensure that the data set we previously cleaned carries over to this segment of the analysis.\n\nfludat_clean <- here::here(\"fluanalysis\",\"data\",\"processed_data\",\"flu_processed\")\nflu_clean <- readRDS(fludat_clean)\n\n\nhist(flu_clean$BodyTemp,col=\"maroon\",main=\"Distribution of Body Temperatures\",\n     xlab=\"Patient Body Temperature\")\nabline(v=c(mean(flu_clean$BodyTemp),median(flu_clean$BodyTemp)),\n       col=c(\"blue\",\"lightblue\"),lty=2)\n\n\n\n\nWe can see that patients’ body temperatures are not normally distributed. Instead, the distribution is skewed toward more extreme values likes 103 degrees Fahrenheit which makes sense as we know this sample is based in flu data, and patients who have the flu typically have elevated temperatures.\nWe may also like to know what percentage of flu sufferers experience nausea. To do this, we can use with() to form a table() centering on the binary outcomes for the Nausea variable (ie. Yes and No).\n\nwith(flu_clean,table(Nausea)) %>%\n    prop.table()\n\nNausea\n       No       Yes \n0.6506849 0.3493151 \n\n\nWe can see that 65% of flu sufferers do not experience any recognizable nausea related symptoms.\n\n\nPlotting\nWe can initialize the general plot format using ggplot() and specifying the data set we will use. This will be useful as we will make a number of plots using this data.\n\nBTplot <- ggplot(flu_clean)\n\nBelow, we use geom_violin() to show the distribution of patients’ temperatures according to whether or not the patient experienced chills or sweats. For all of the subsequent graphs, we have to specify which explanatory and response variables we want to use. To accomplish this, we must use the scheme aes(x=,y=). For differentiation (and for fun), we also include a fill color to help differentiate between graphs.\n\nBTplot +\ngeom_violin(aes(ChillsSweats,BodyTemp),fill=\"red\")\n\n\n\n\nWe see that patients who experience chills or sweats have a slightly higher temperature compared to patients who do not claim to experience chills or sweats. Using a two-way table, we can get a relative idea of how related the response variable is to the explanatory variable. We use the same method as before to create a table of the data, but this time, we specify two arguments to generate the 2-way table. Also, we can convert the table into a table of proportions by using prop.table().\n\nwith(flu_clean,table(ChillsSweats,Nausea)) %>%\n    prop.table()\n\n            Nausea\nChillsSweats        No       Yes\n         No  0.1410959 0.0369863\n         Yes 0.5095890 0.3123288\n\n\nBased on the above table, we can see that the largest proportion of flu sufferers do experience chills and sweats, but the majority of flu sufferers do not experience both chills/sweats and nausea.\nThe graph below shows the distribution of patient temperatures based on whether or not they experienced vomiting as a symptom of the flu.\n\nBTplot +\ngeom_violin(aes(Vomit,BodyTemp),fill=\"orange\")\n\n\n\n\n\nwith(flu_clean,table(Vomit,Nausea)) %>%\n    prop.table()\n\n     Nausea\nVomit         No        Yes\n  No  0.63150685 0.26164384\n  Yes 0.01917808 0.08767123\n\n\nAccording to both the plot and table above, we see that most flu sufferers do not experience vomiting as a symptom, but for those that do, nausea is a commonly reported co-symptom.\nBelow is the distribution of patients’ body temperatures stratified by fatigue status.\n\nBTplot +\ngeom_violin(aes(Fatigue,BodyTemp),fill=\"yellow\")\n\n\n\n\n\nwith(flu_clean,table(Fatigue,Nausea)) %>%\n    prop.table()\n\n       Nausea\nFatigue         No        Yes\n    No  0.06986301 0.01780822\n    Yes 0.58082192 0.33150685\n\n\nBased on the plot and table above, we do not see very interesting changes due to stratification.\nBelow, you can find the violin plot of patients’ temperatures according to whether or not the patient had swollen lymph nodes.\n\nBTplot +\ngeom_violin(aes(SwollenLymphNodes,BodyTemp),fill=\"green\")\n\n\n\n\n\nwith(flu_clean,table(SwollenLymphNodes,Nausea)) %>%\n    prop.table()\n\n                 Nausea\nSwollenLymphNodes        No       Yes\n              No  0.3767123 0.1958904\n              Yes 0.2739726 0.1534247\n\n\nSimilarly to the interactions we see with fatigue and nausea, we do not see a very substantial change due to stratification by presence of swollen lymph nodes. Interestingly, the proportions are fairly evenly distributed between all four possible outcomes, meaning the interaction between nausea and swollen lymph nodes is likely zero.\nThe next couple explanatory variables will be interesting as they are not binary outcomes. The interactions may be more difficult to see, but they will be interesting to study.\n\nBTplot +\ngeom_violin(aes(Weakness,BodyTemp),fill=\"blue\")\n\n\n\n\n\nwith(flu_clean,table(Weakness,Nausea)) %>%\n    prop.table()\n\n          Nausea\nWeakness           No        Yes\n  None     0.05342466 0.01369863\n  Mild     0.23561644 0.06986301\n  Moderate 0.28767123 0.17534247\n  Severe   0.07397260 0.09041096\n\n\nBased on the figure above, we can see a slight increase in the mean body temperature as weakness severity increases. Using the table, we see that, amongst nausea sufferers, there is a larger proportion of patients who also experienced high levels of weakness.\n\nBTplot +\ngeom_violin(aes(CoughIntensity,BodyTemp),fill=\"purple\")\n\n\n\n\n\nwith(flu_clean,table(CoughIntensity,Nausea)) %>%\n    prop.table()\n\n              Nausea\nCoughIntensity         No        Yes\n      None     0.04109589 0.02328767\n      Mild     0.13561644 0.07534247\n      Moderate 0.31780822 0.17123288\n      Severe   0.15616438 0.07945205\n\n\nWe see a similar trend in coughing intensity as with weakness level; with nausea, the higher the proportion of individuals who experienced moderate or severe coughing fits.\n\n\nConclusions\nWe may consider checking the relationships between the response variables and the following predictors:\n~Chills/Sweats (binary, yes/no)\n~Fatigue (binary, yes/no)\n~Weakness (cat.)"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "FluAnalysis",
    "section": "",
    "text": "We begin by using the library function to be able to use the tidyverse packages\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nWe use the here() function from the here package to identify the file location and use readRDS to import the .Rda file.\n\nfludat_raw <- here::here(\"fluanalysis\",\"data\",\"raw_data\",\"SympAct_Any_Pos.Rda\")\nflu_raw <- readRDS(fludat_raw)\n\nWe use the anyNA() function to indicate whether there are any missing values in the original data set. Also, we can use the !c() to make a subset of all the variables we do not want to include. On top of this, we can use dplyr’s select() to choose the variables we want to include in the new data set. Finally, we apply drop_na() to exclude any missing data. At the end, we validate that out analyses excluded all missing data using anyNA() on the new data set.\n\nanyNA(flu_raw)\n\n[1] TRUE\n\nflu_clean <- flu_raw %>%\n                select(!c(contains(c(\"Score\",\"Total\",\"FluA\",\"FluB\",\n                                     \"Dxname\",\"Activity\")),\"Unique.Visit\")) %>%\n                drop_na()\nanyNA(flu_clean)\n\n[1] FALSE\n\n\nAgain, we use the here() function to clearly indicate where the RDS file should be saved. We use saveRDS() to save the data set as the proper file type.\n\nfludat_clean <- here::here(\"fluanalysis\",\"data\",\"processed_data\",\"flu_processed\")\nsaveRDS(flu_clean,file=fludat_clean)"
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "FluAnalysis",
    "section": "",
    "text": "We begin by using the library function to be able to use the tidymodels packages\nWe must also ensure that the data set we previously cleaned carries over to this segment of the analysis.\nWe can create the general models we will use by setting the engine with set_engine() for linear and logistic regression, repsectively."
  },
  {
    "objectID": "fluanalysis/code/fitting.html#linear-regression",
    "href": "fluanalysis/code/fitting.html#linear-regression",
    "title": "FluAnalysis",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nRestrictive Model\nWe first fit the model predicting temperature from having a runny nose:\n\nlm_fit1 <- linear %>%\n            fit(BodyTemp~RunnyNose,data=flu_clean)\n# By using the tidy function, we can convert the resulting list into an easy to read table\n# From there, we can also create a dot and whisker plot to demonstrate the relative size\n# of the estimates\nbroom::tidy(lm_fit1) %>%\n      dotwhisker::dwplot(vline = \n# Creates a vertical line to visualize no association\n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nWe see that the regression coefficient relating runny nose status and body temperature is about -0.3. ### Other Models No we will see how this compares to a less restrictive model by using more predictors:\n\nlm_fit2 <- linear %>%\n            fit(BodyTemp~RunnyNose * ChillsSweats * Fatigue * Weakness,\n                data=flu_clean)\nbroom::tidy(lm_fit2) %>%\n      dotwhisker::dwplot(vline = \n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nUsing 3 more predictors for body temperature, we get 32 different coefficients relating body temperature to each prediction and their associated interactions. We can see that this model may be too complex for interpretation.\nInstead, we may want to look at how 2 or 3 predictors could impact the results:\n\nlm_fit2 <- linear %>%\n            fit(BodyTemp~RunnyNose * Weakness,\n                data=flu_clean)\nbroom::tidy(lm_fit2) %>%\n      dotwhisker::dwplot(vline = \n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nThis model is easier to use and make predictions from but is still less restrictive than the original model."
  },
  {
    "objectID": "fluanalysis/code/fitting.html#logistic-regression",
    "href": "fluanalysis/code/fitting.html#logistic-regression",
    "title": "FluAnalysis",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nRestrictive Model\nWe first fit the model predicting nausea from having a runny nose:\n\nlog_fit1 <- logit %>%\n            fit(Nausea~RunnyNose, data=flu_clean)\n# By using the tidy function, we can convert the resulting list into an easy to read table\n# From there, we can also create a dot and whisker plot to demonstrate the relative size\n# of the estimates\nbroom::tidy(log_fit1) %>%\n      dotwhisker::dwplot(vline = \n# Creates a vertical line to visualize no association\n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nWe see that the regression coefficient relating runny nose status and nausea is depicted above with it’s 95% CI. The coefficient estimate is about 0.05.\n\n\nOther Models\nNow let’s fit a less restrictive model:\n\nlog_fit2 <- logit %>%\n            fit(Nausea~RunnyNose * ChillsSweats * Fatigue * Weakness, data=flu_clean)\nbroom::tidy(log_fit2) %>%\n      dotwhisker::dwplot(vline = \n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nWe see that, again, the model is too crowded for much meaningful interpretation. We do notice the much wider ranges of values obtained by the model. Likely, the effect size is so diluted by the vast number of predictors used in the model. If more predictors are introduced, the ranges of values will also increase exponentially larger.\nInstead, let’s try looking at something a little simpler but still less restrictive than the original model:\n\nlog_fit2 <- logit %>%\n            fit(Nausea~RunnyNose * Weakness, data=flu_clean)\nbroom::tidy(log_fit2) %>%\n      dotwhisker::dwplot(vline = \n                           geom_vline(xintercept = 0, \n                                      colour = \"black\", \n                                      linetype = 2))\n\n\n\n\nHere, we can see relative effect that each predictor has on the outcome. Simply, we see that severe weakness is strongly associated with increased nausea."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Flu Analysis",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ broom        1.0.3     ✔ recipes      1.0.5\n✔ dials        1.1.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.0     ✔ tibble       3.1.8\n✔ ggplot2      3.4.1     ✔ tidyr        1.2.1\n✔ infer        1.0.4     ✔ tune         1.0.1\n✔ modeldata    1.1.0     ✔ workflows    1.1.3\n✔ parsnip      1.0.4     ✔ workflowsets 1.0.0\n✔ purrr        0.3.4     ✔ yardstick    1.1.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.2     ✔ forcats 0.5.2\n✔ stringr 1.4.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nWe will be using the data from the cleaned flu analysis data, so we will need to load the data from the processed_data folder.\nWe’ll then need to find a way to create a dummy data set, called the test data set, from the cleaned data. We will use this data to test the efficacy of the generated model. We will use the remaining data, the training data set, to fit the model.\nTo attempt this, we will set a seed with set.seed() for randomization to ensure that these processes are reproducible. Further, we use initial_split() from the rsample package to generate a splitting rule for the training and test data sets.\nWe intend to use the tidymodels workflow to generate our logistic regression model. Within this workflow, we use recipe() and worklfow() to identify the relationships of interest.\nNow that we have generated the workflow, we can fit the model to the training and test data sets, respectively.\nWe now want to compare the estimates. To do this, we use augment().\nIf we want to assess how well the model makes predictions, we can evaluate this with an ROC curve. roc_curev() and autoplot() will prepare the plot for us to evaluate the model on the training_data and the test_data, separately.\nroc_auc() estimates the area under the ROC curve. An area close to 1 means a good prediction, while an area near 0.5 means the model is of poor predictive quality.\nWe repeat the same steps above for the test_data.\nOverall, the model appears to predict the data fairly well since both the training and test data have an area under the curve >0.7.\nPart 2 Let’s see how a more restrictive model would act.\nNow, let’s choose only 1 predictor instead of using all of them.\nThe ROC curve of the training data set:\nThe model is not a good fit of the data.\nThe ROC curve of the test data set:\nThe model is not a good fit of the data."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#linear-model-for-continuous-outcome-bodytemp",
    "href": "fluanalysis/code/modeleval.html#linear-model-for-continuous-outcome-bodytemp",
    "title": "Flu Analysis",
    "section": "Linear model for continuous outcome BodyTemp",
    "text": "Linear model for continuous outcome BodyTemp\n\nCreating workflow and fitting model using all predictors\n\n# Creating recipe and set up dummy code for all categorical variables\nset.seed(123)\ntemp_rec=recipe(BodyTemp~.,data=training_data)%>%\n  step_dummy(all_nominal())\n# Training linear regression model\nlm_mod=linear_reg()%>%\n  set_engine(\"lm\")\n# Creating workflow\ntemp_workflow=workflow()%>%\n  add_model(lm_mod)%>%\n  add_recipe(temp_rec)\ntemp_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\ntemp_fit=temp_workflow%>%\n  fit(data=training_data)\n# Checking the parameter estimates and arrange their respective p.values\ntemp_fit%>%\n  extract_fit_parsnip()%>%\n  tidy()%>%\n  arrange(p.value)\n\n# A tibble: 38 × 5\n   term                estimate std.error statistic  p.value\n   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)           98.1       0.354    277.   0       \n 2 SubjectiveFever_Yes    0.430     0.120      3.59 0.000372\n 3 Sneeze_Yes            -0.310     0.115     -2.69 0.00731 \n 4 Headache_Yes          -0.340     0.148     -2.30 0.0218  \n 5 Pharyngitis_Yes        0.322     0.141      2.29 0.0226  \n 6 Fatigue_Yes            0.424     0.187      2.26 0.0241  \n 7 Vision_Yes            -0.643     0.297     -2.16 0.0310  \n 8 Weakness_Severe        0.515     0.262      1.97 0.0495  \n 9 ChillsSweats_Yes       0.274     0.153      1.79 0.0746  \n10 Myalgia_Severe        -0.425     0.247     -1.72 0.0862  \n# … with 28 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nUse the trained workflow to predict both training and testing data\n\n# Predicting training dataand getting model metrics\npredict(temp_fit,training_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 510 × 1\n   .pred\n   <dbl>\n 1 100. \n 2  99.6\n 3  98.5\n 4  99.8\n 5  99.7\n 6 100. \n 7  99.1\n 8  99.2\n 9  98.6\n10  98.7\n# … with 500 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\ntemp_aug_train=augment(temp_fit,training_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\ntemp_aug_train%>%\n  metrics(truth = !!sym(\"BodyTemp\"), estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       1.06 \n2 rsq     standard       0.165\n3 mae     standard       0.793\n\n# Predicting testing data and getting model metrics\npredict(temp_fit,test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 220 × 1\n   .pred\n   <dbl>\n 1  99.1\n 2  99.6\n 3  98.9\n 4  99.1\n 5  99.0\n 6  98.3\n 7  98.8\n 8  99.6\n 9  99.4\n10 100. \n# … with 210 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\ntemp_aug_test=augment(temp_fit,test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\ntemp_aug_test%>%\n  metrics(truth = !!sym(\"BodyTemp\"), estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      1.28  \n2 rsq     standard      0.0246\n3 mae     standard      0.967 \n\n\n\n\nCreating workflow and fitting model using the main predictor (RunnyNose)\n\nset.seed(234)\ntemp_rec2=recipe(BodyTemp~RunnyNose,data=training_data)\n# Training linear regression model\nlm_mod=linear_reg()%>%\n  set_engine(\"lm\")\n# Creating workflow\ntemp_workflow2=workflow()%>%\n  add_model(lm_mod)%>%\n  add_recipe(temp_rec2)\ntemp_workflow2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\ntemp_fit2=temp_workflow2%>%\n  fit(data=training_data)\n# Checking the parameter estimates and arrange their respective p.values\ntemp_fit2%>%\n  extract_fit_parsnip()%>%\n  tidy()%>%\n  arrange(p.value)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0948   1046.    0     \n2 RunnyNoseYes   -0.278    0.113      -2.47  0.0140\n\n\n\n\nUse the trained workflow to predict both training and testing data\n\n# Predicting training data and getting model metrics\npredict(temp_fit2,training_data)\n\n# A tibble: 510 × 1\n   .pred\n   <dbl>\n 1  98.9\n 2  98.9\n 3  98.9\n 4  99.1\n 5  98.9\n 6  98.9\n 7  98.9\n 8  99.1\n 9  98.9\n10  98.9\n# … with 500 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\ntemp_aug_train2=augment(temp_fit2,training_data)\ntemp_aug_train2%>%\n  metrics(truth = !!sym(\"BodyTemp\"), estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      1.16  \n2 rsq     standard      0.0118\n3 mae     standard      0.834 \n\n# Predicting testing data and getting model metrics\npredict(temp_fit2,test_data)\n\n# A tibble: 220 × 1\n   .pred\n   <dbl>\n 1  99.1\n 2  99.1\n 3  98.9\n 4  99.1\n 5  98.9\n 6  98.9\n 7  98.9\n 8  98.9\n 9  98.9\n10  99.1\n# … with 210 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\ntemp_aug_test2=augment(temp_fit2,test_data)\ntemp_aug_test2%>%\n  metrics(truth = !!sym(\"BodyTemp\"), estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      1.25  \n2 rsq     standard      0.0134\n3 mae     standard      0.949 \n\n\n\nOverall, the model built and trained based on all predictors has a higher RMSE than that built and trained based on the main predictor RunnyNose.\n```"
  }
]